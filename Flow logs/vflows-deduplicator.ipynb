{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e6eb89e-dca4-4d68-967f-f64706c42985",
   "metadata": {},
   "source": [
    "#### VPC Flow Logs De-Duplicator: Cut Flow Log Cost Down to Size.\n",
    "This notebook ingests VPC flow logs from a folder into a dataframe and de-duplicates them. VPC flow logs resemble netflow in that each flow has source and destination IPs and ports and a protocol. It tends to compress even better than netflow because a given TCP session will produce many vpc flow logs records for the session where only the byte and packet counts are different.\n",
    "\n",
    "These can be de-duplicated into one record with a sum of bytes and packets and a start / end timestamp. With compression ratios as high as 30x, the cost of storage and processing can be massively reduced, making vpc flow logs more palatable to organizations where the processing and storage cost deters collection and analysis of this data. In addition, this can be done in the VPC where the flow logs reside, eliminating the cost associated with exporting them into a third party SaaS tool. "
   ]
  },
  {
   "cell_type": "raw",
   "id": "003bd3da-b2a6-467e-9847-e26b938fbe86",
   "metadata": {
    "tags": []
   },
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c1def4-a0c0-44f1-b39d-97d902b913ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 10)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', 50)\n",
    "pd.set_option('display.expand_frame_repr', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9d2d95-9abb-42de-8f39-dcf805f5abd8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the folder name to ingest vpc flow logs\n",
    "\n",
    "root_dir = r\"2024\"\n",
    "\n",
    "\n",
    "dataframes = []\n",
    "\n",
    "\n",
    "for subdir, dirs, files in os.walk(root_dir):\n",
    "    for file in files:\n",
    "        \n",
    "        if file.endswith(\".log\"):\n",
    "            file_path = os.path.join(subdir, file)\n",
    "            \n",
    "            df = pd.read_csv(file_path, delimiter=' ')  \n",
    "            dataframes.append(df)\n",
    "\n",
    "\n",
    "vflows = pd.concat(dataframes, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bbaf1e20-be35-426d-815f-49617bae6674",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Optionally import flows from a csv file \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2ebed15c-5148-41f2-8d60-f2148963e4bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Process duplicate flow\n",
    "\n",
    "duplicate_rows = vflows.duplicated(\n",
    "    subset=['account-id', 'interface-id', 'srcaddr', 'dstaddr', 'srcport', 'dstport', 'protocol', 'action'], \n",
    "    keep=False\n",
    ")\n",
    "duplicates = vflows[duplicate_rows]\n",
    "\n",
    "duplicate_counts = duplicates.groupby(\n",
    "    ['account-id', 'interface-id', 'srcaddr', 'dstaddr', 'dstport', 'srcport', 'protocol', 'action']\n",
    ").agg(\n",
    "    count=('account-id', 'size'),       \n",
    "    total_bytes=('bytes', 'sum'),      \n",
    "    total_packets=('packets', 'sum')   \n",
    ").reset_index()\n",
    "\n",
    "duplicate_counts = duplicate_counts.sort_values(by='count', ascending=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "20030a47-fa23-4eba-b7d3-59a43b4960c3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The raw flow logs contained 10,692,493 records.\n",
      "They deduped down to: 382,608 records.\n",
      "The compression ratio of raw to de-duplicated records is 27.95!\n",
      "The size of the raw DataFrame is 7,170,529,574 bytes.\n",
      "The size of the de-duplicated DataFrame is 239,448,265 bytes.\n",
      "The memory saved is 6,931,081,309 bytes!\n",
      "Long live the fighters!\n"
     ]
    }
   ],
   "source": [
    "# Report output stats\n",
    "if duplicate_counts.shape[0] > 0:  \n",
    "    ratio = vflows.shape[0] / duplicate_counts.shape[0]\n",
    "    print(f\"The raw flow logs contained {vflows.shape[0]:,} records.\")\n",
    "    print(f\"They deduped down to: {duplicate_counts.shape[0]:,} records.\")\n",
    "    print(f\"The compression ratio of raw to de-duplicated records is {ratio:,.2f}!\")\n",
    "else:\n",
    "    print(\"No deduplicated records to calculate a ratio.\")\n",
    "\n",
    "size_raw = vflows.memory_usage(deep=True).sum()\n",
    "size_deduped = duplicate_counts.memory_usage(deep=True).sum()\n",
    "\n",
    "size_difference = size_raw - size_deduped\n",
    "single_row_counts = vflows.groupby(\n",
    "    ['account-id', 'interface-id', 'srcaddr', 'dstaddr', 'dstport', 'srcport', 'protocol', 'action']\n",
    ").size().reset_index(name='row_count')\n",
    "\n",
    "print(f\"The size of the raw DataFrame is {size_raw:,} bytes.\")\n",
    "print(f\"The size of the de-duplicated DataFrame is {size_deduped:,} bytes.\")\n",
    "print(f\"The memory saved is {size_difference:,} bytes!\")\n",
    "print(\"Long live the fighters!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4817767f-b73b-44f1-88f4-a95edff2db7e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8,761,159 single flow runts were excluded\n",
      "These break down as follows:\n",
      "   action      count\n",
      "0  REJECT  6,233,838\n",
      "1  ACCEPT  2,527,321\n"
     ]
    }
   ],
   "source": [
    "# Count runts consisting of a single flow by action\n",
    "# With Internet facing IPs, there will tend to be many single flow connections \n",
    "# due to scanning and enumeration activity. These are often low impact.\n",
    "single_row_counts = vflows.groupby(\n",
    "    ['account-id', 'interface-id', 'srcaddr', 'dstaddr', 'dstport', 'srcport', 'protocol', 'action']\n",
    ").size().reset_index(name='row_count')\n",
    "\n",
    "single_row_groups = single_row_counts[single_row_counts['row_count'] == 1]\n",
    "action_counts = single_row_groups['action'].value_counts().reset_index()\n",
    "action_counts.columns = ['action', 'count']\n",
    "action_counts['count'] = action_counts['count'].replace(',', '', regex=True).astype(int)\n",
    "action_counts['count'] = action_counts['count'].apply(lambda x: f\"{x:,}\")\n",
    "\n",
    "total_excluded = single_row_groups.shape[0]\n",
    "print(f\"{total_excluded:,} single flow runts were excluded\")\n",
    "print(\"These break down as follows:\")\n",
    "print(action_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6689534d-d913-4b76-b3d1-b77f4b98b477",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cast the fields post-processing to save time\n",
    "duplicate_counts['bytes'] = pd.to_numeric(duplicate_counts['bytes'], errors='coerce')\n",
    "duplicate_counts['packets'] = pd.to_numeric(duplicate_counts['packets'], errors='coerce')\n",
    "duplicate_counts['start'] = pd.to_datetime(duplicate_counts['start'], unit='s')\n",
    "duplicate_counts['end'] = pd.to_datetime(duplicate_counts['end'], unit='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a254328f-569d-40bd-9ab8-bfa592cc87e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optionally output to csv for sharing\n",
    "ddf.to_csv('ddf.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec409e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally output to excel for sharing\n",
    "duplicate_counts.to_excel('dedup.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
