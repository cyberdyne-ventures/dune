{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c582d53f-3c8d-46f3-aac8-59d41ff613c1",
   "metadata": {},
   "source": [
    "Simple Flow Log Loader and Summarizer\n",
    "\n",
    "This notebook loads vpc flow logs from a folder into a dataframe for analysis. After loading, several subsets are created.\n",
    "In order to look for C2 or exfiltration activity, a derivative data frame is created containing north / south traffic. Definitions:\n",
    "\n",
    "North / south traffic: flows with a source or destination that is remote on the Internet - traffic to or from the Internet.\n",
    "East / west traffic: flows with private source and destination IPs - local traffic that does not leave the VPC.\n",
    "\n",
    "North / south is a good place to start because a lot of what we’re looking for during threat hunting - initial access, credentialed access, C2, and exfiltration, requires north / south traffic. East / west traffic can be a place to hunt lateral movement but that requires more complex analytics, using different approaches, because most local traffic is benign and voluminous. \n",
    "\n",
    "The notebook generates a subset of flows containing north / south traffic and then counts the top 1000 Internet destination IPS by flow count volume. I’ll do counts by data volume in a forthcoming notebook. After that, the top 200 destination IPs are labeled with their AS (autonomous system) network and country names. Cloud providers, and OS vendors, are excluded here because most of this is benign, most of the time, and hunting intra-cloud threat traffic also requires different analytics. The lookups are limited to the top 200 because there are rate limits and trying to do all 1000 at once will tend to be too many. \n",
    "\n",
    "Finally, a deduplication function in the pandas project can be used to summarize the activity for an IP address. When you have an IP / ASN / country combination that cannot be reconciled to normal business activity, or is otherwise believed to be threat traffic, deduplication can be used to summarize the traffic in order to ask these questions:\n",
    "Is the activity inbound, focused on a single port, with similar byte / packet counts? This is often scanning and discovery activity which may not have much impact unless a vuln was exploited and a host started doing what looks like C2.\n",
    "Is the activity inbound, with large flow, packet and and byte counts, to an RDP or SSH port? That could be credentialed access if it cannot be accounted for as admin activity.\n",
    "Is the activity outbound, with many small packets destined for one port? That could be C2 or some sort of telemetry or auto update mechanism depending on where it is going.\n",
    "Is the activity outbound, to a single port, with large flow, packet and and byte counts? This can be exfiltration, if it cannot be reconciled as normal data movement. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d58455-9e87-4a03-9886-01266ff5d25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipaddress\n",
    "from ipwhois import IPWhois\n",
    "from ipwhois.exceptions import IPDefinedError, HTTPLookupError\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4cc726-e89f-409b-9053-01dab7cf4847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For loading flow logs in folders downloaded from S3 (unzip them first)\n",
    "# Recurse through a folder and ingest flow logs (path goes in the first param)\n",
    "\n",
    "file_pattern = os.path.join('06', '**', '*.log')\n",
    "files = glob.glob(file_pattern, recursive=True)\n",
    "df_list = []\n",
    "\n",
    "for file in files:\n",
    "    try:\n",
    "        if os.path.getsize(file) > 0:\n",
    "            df = pd.read_csv(file, delim_whitespace=True)  # or sep='\\t' for tab-separated\n",
    "            df_list.append(df)\n",
    "        else:\n",
    "            print(f\"Skipping empty file: {file}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {file}: {e}\")\n",
    "\n",
    "if df_list:\n",
    "   flows = pd.concat(df_list, ignore_index=True)\n",
    "   print(flows)\n",
    "else:\n",
    "    print(\"No data frames were read successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dad7720-7a8c-43dc-8c0b-ba85d23efdba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for when you have a saved set of previosuly ingested flows\n",
    "# flows = pd.read_csv('flows.csv', low_memory = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7192ab14-7f2d-49f6-8a5a-42d3405f8968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the columns to string for searching, then check if any contain '-' character\n",
    "invalid_rows = flows[\n",
    "    flows['dstaddr'].astype(str).str.contains('-') |\n",
    "    flows['srcaddr'].astype(str).str.contains('-') |\n",
    "    flows['dstport'].astype(str).str.contains('-') |\n",
    "    flows['protocol'].astype(str).str.contains('-') |\n",
    "    flows['bytes'].astype(str).str.contains('-') |\n",
    "    flows['packets'].astype(str).str.contains('-')\n",
    "]\n",
    "# Display the rows where '-' appears in one of the columns\n",
    "invalid_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17e1522-eb50-46f9-9cad-bcd5e4e1eef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete these problem row(s) with invalid values or fix then and re-ingest\n",
    "flows = flows.drop(index=55745)\n",
    "flows.reset_index(drop=True, inplace=True)\n",
    "flows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993910c6-be55-46cd-8095-b7dcee341d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert bytes and packets values to numeric, convert the timestamps to readable formats\n",
    "flows['end'] = pd.to_datetime(flows['end'], unit='s')\n",
    "flows['start'] = pd.to_datetime(flows['start'], unit='s')\n",
    "\n",
    "flows['dstport'] = flows['dstport'].astype(int)\n",
    "flows['bytes'] = flows['bytes'].astype(int)\n",
    "flows['packets'] = flows['packets'].astype(int)\n",
    "flows['protocol'] = flows['protocol'].astype(int)\n",
    "print(flows['dstport'].dtype)\n",
    "print(flows['protocol'].dtype)\n",
    "print(flows['packets'].dtype)\n",
    "print(flows['bytes'].dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ebc856-6490-4be9-9185-81e0530a830b",
   "metadata": {},
   "outputs": [],
   "source": [
    "flows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256d4bf1-f22d-4fc6-847e-6ab418b37765",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a subset dataframe (ns) for north / south traffic flows\n",
    "# north / south traffic transits the Internet vs. east / west inside the VPC\n",
    "\n",
    "def is_private_ip(ip):\n",
    "    try:\n",
    "        return ipaddress.ip_address(ip).is_private\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "ns = flows.copy()\n",
    "ns = ns[ns['action'] == 'ACCEPT']\n",
    "ns = ns[~(ns['srcaddr'].apply(is_private_ip) & ns['dstaddr'].apply(is_private_ip))]\n",
    "ns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431212e2-e43f-4b15-8d85-00d461d6530a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove NTP traffic, there will be a lot of benign ntp activity in most fleets. We need a list but this will work\n",
    "\n",
    "filtered_ns = ns[\n",
    "    ~(\n",
    "        (ns['dstport'] == 123) &\n",
    "        (ns['protocol'] == 17) &\n",
    "        (ns['packets'] == 1) &\n",
    "        (ns['bytes'] == 76)\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2cf45c-ee2f-4b8c-a6b4-b2169d7dbab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spot check that the majority of ntp flows are indeed gone\n",
    "\n",
    "ntp = filtered_ns[(filtered_ns['dstport'] == 123) ]\n",
    "ntp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66a511a-bb02-4a63-9744-967555c85029",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out rows where dstaddr is a private IP address to match extrusion and get rid of rejects\n",
    "# Group by the specified fields and count the top flows by volume\n",
    "\n",
    "filtered_ns = filtered_ns[~filtered_ns['dstaddr'].apply(is_private_ip)]\n",
    "top_combinations = filtered_ns.groupby(['account-id', 'interface-id', 'srcaddr', 'dstaddr', 'dstport', 'protocol', 'action']).size().reset_index(name='flow_count')\n",
    "top_combinations = top_combinations.sort_values(by='flow_count', ascending=False).head(1000)\n",
    "top_combinations.reset_index(drop=True, inplace=True)\n",
    "\n",
    "top_combinations[top_combinations['action'] == 'ACCEPT']\n",
    "pd.options.display.max_rows = 200\n",
    "top_combinations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325fe1b8-298d-4408-ba40-a2f2ddccbf34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get ASN information\n",
    "def get_whois_info(ip):\n",
    "    try:\n",
    "        obj = IPWhois(ip)\n",
    "        res = obj.lookup_rdap()\n",
    "        asn = res.get('asn', 'N/A')\n",
    "        org = res.get('network', {}).get('name', 'N/A')\n",
    "        country = res.get('network', {}).get('country', 'N/A')\n",
    "        return pd.Series([asn, org, country])\n",
    "    except (IPDefinedError, HTTPLookupError, ValueError) as e:\n",
    "        print(f\"Error looking up {ip}: {e}\")\n",
    "        return pd.Series(['N/A', 'N/A', 'N/A'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293472f7-aad0-4eb6-9932-781458b0c1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of ASN names to be excluded - cloud2cloud traffic requires different analytics so let's look at extrusion\n",
    "# excluding cloud providers in order to focus on extrusion\n",
    "# don't try to do lookups on thousands of IPs, you will run into rate limiting\n",
    "\n",
    "asn_exclude_list = ['AMAZON-02', 'AMAZON-IAD', 'AT-88-Z', 'AMAZON-2011L', 'AMAZO-CF', 'GOOGLE', 'GOOGLE-CLOUD', 'GOOGL-2', \\\n",
    "                    'UK-CANONICAL-20151111', 'CANONICAL-CORE', \\\n",
    "                    'MICROSOFT', 'MSFT']\n",
    "top_combinations = top_combinations.head(200)\n",
    "lookup_results_dst = top_combinations['dstaddr'].apply(get_whois_info)\n",
    "lookup_df_dst = pd.DataFrame(lookup_results_dst.values.tolist(), index=lookup_results_dst.index, columns=['ASN_dst', 'Organization_dst', 'Country_dst'])\n",
    "lookup_df = pd.concat([top_combinations, lookup_df_dst], axis=1)\n",
    "\n",
    "lookup_df = lookup_df[~lookup_df['Organization_dst'].isin(asn_exclude_list)]\n",
    "lookup_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cfc1709-58ca-4fa8-a93b-a07d9880527d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize traffic for a destination IP by sources and destination ports using deduplication\n",
    "# This allows for quick analysis of the nature of the traffic by summation\n",
    "# Try removing either srcport or dstport depending on whether this is inbound or outbound traffic\n",
    "# Define the target IP address to filter\n",
    "\n",
    "target_ip = '1.2.3.4'  \n",
    "\n",
    "search = filtered_ns[(filtered_ns['dstaddr'] == target_ip)]\n",
    "result = search.drop_duplicates(subset=['account-id', 'srcaddr', 'srcport', 'dstaddr', 'dstport',  'protocol', 'action'], keep='last')\n",
    "result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81744c47-7c22-4154-a705-146aa775cacc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
